{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "test_df = pd.read_csv(\"data/test.csv\")\n",
    "ex_df = pd.read_csv(\"data/gender_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理のメモ\n",
    "- PassengerId\n",
    "- Survived: 生きているかどうか 0 or 1\n",
    "\n",
    "\n",
    "- Age: 年齢 欠損値あり\n",
    "  - Pclass, Sex, Parch, SibSp からランダムフォレストで推定\n",
    "- SibSp: 兄弟姉妹の数\n",
    "- Parch: 親子の数\n",
    "- Fare: 運賃 欠損値あり\n",
    "  - Pclass, Sex, Parch, SibSp から平均値で補完\n",
    "\n",
    "### Nanとそれ以外で分ける\n",
    "- Cabin: 客室番号 欠損値あり\n",
    "\n",
    "### 不要な列\n",
    "- Name: 名前\n",
    "- Ticket: チケットの番号\n",
    "\n",
    "### ワンホットエンコーディング\n",
    "- Pclass: チケットのクラス 1, 2, 3\n",
    "- Sex: 性別\n",
    "- Embarked: 乗船場所 S, C, Q 欠損値あり\n",
    "  - 欠損値の2人（全て）は生き残っていた\n",
    "  - 欠損値の時は生存率が高かったCで補完することにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId       0\n",
       "Survived        418\n",
       "Pclass            0\n",
       "Name              0\n",
       "Sex               0\n",
       "Age             263\n",
       "SibSp             0\n",
       "Parch             0\n",
       "Ticket            0\n",
       "Fare              1\n",
       "Cabin          1014\n",
       "Embarked          2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df, test_dfを結合\n",
    "test_df[\"Survived\"] = np.nan\n",
    "df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived       418\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            263\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin            0\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CabinはNaNの場合は0, それ以外は1\n",
    "df[\"Cabin\"] = df[\"Cabin\"].notnull().astype(int)\n",
    "\n",
    "# Embarkedは欠損値の2人はCで補完する\n",
    "df[\"Embarked\"] = df[\"Embarked\"].fillna(\"C\")\n",
    "\n",
    "# Fareは欠損値をPclass, Sex, Parch, SibSpの平均値で補完する\n",
    "df['Fare'] = df['Fare'].fillna(df.groupby(['Pclass', 'Sex', 'Parch', 'SibSp'])['Fare'].transform('mean'))\n",
    "\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age を Pclass, Sex, Parch, SibSp からランダムフォレストで推定\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "age_df = df[[\"Age\", \"Pclass\", \"Sex\", \"Parch\", \"SibSp\"]]\n",
    "age_df = pd.get_dummies(age_df, columns=[\"Pclass\", \"Sex\"])\n",
    "\n",
    "# 学習データとテストデータに分離\n",
    "known_age = age_df[age_df.Age.notnull()].values\n",
    "unknown_age = age_df[age_df.Age.isnull()].values\n",
    "\n",
    "# 学習データをX, yに分離\n",
    "X_train = known_age[:, 1:]\n",
    "y_train = known_age[:, 0]\n",
    "\n",
    "# ランダムフォレストで推定モデルを構築\n",
    "rfr = RandomForestRegressor(random_state=0, n_estimators=100, n_jobs=-1)\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "# 補完\n",
    "predictedAges = rfr.predict(unknown_age[:, 1::])\n",
    "df.loc[(df.Age.isnull()), \"Age\"] = predictedAges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 年齢別生存曲線と死亡曲線\n",
    "# facet = sns.FacetGrid(df[0:890], hue=\"Survived\", aspect=2)\n",
    "# facet.map(sns.kdeplot, \"Age\", shade=True)\n",
    "# facet.set(xlim=(0, df.loc[0:, \"Age\"].max()))\n",
    "# facet.add_legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不要な列を削除\n",
    "df.drop([\"Name\", \"Ticket\"], axis=1, inplace=True)\n",
    "\n",
    "# ワンホットエンコーディング\n",
    "df = pd.get_dummies(df, columns=[\"Pclass\", \"Sex\", \"Embarked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived   Age  SibSp  Parch     Fare  Cabin  Pclass_1  \\\n",
       "0            1       0.0  22.0      1      0   7.2500      0     False   \n",
       "1            2       1.0  38.0      1      0  71.2833      1      True   \n",
       "2            3       1.0  26.0      0      0   7.9250      0     False   \n",
       "3            4       1.0  35.0      1      0  53.1000      1      True   \n",
       "4            5       0.0  35.0      0      0   8.0500      0     False   \n",
       "\n",
       "   Pclass_2  Pclass_3  Sex_female  Sex_male  Embarked_C  Embarked_Q  \\\n",
       "0     False      True       False      True       False       False   \n",
       "1     False     False        True     False        True       False   \n",
       "2     False      True        True     False       False       False   \n",
       "3     False     False        True     False       False       False   \n",
       "4     False      True       False      True       False       False   \n",
       "\n",
       "   Embarked_S  \n",
       "0        True  \n",
       "1       False  \n",
       "2        True  \n",
       "3        True  \n",
       "4        True  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "# 前処理終了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/otsukanaoya/Desktop/programming/kaggle/competition-titanic/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/otsukanaoya/Desktop/programming/kaggle/competition-titanic/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/otsukanaoya/Desktop/programming/kaggle/competition-titanic/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/otsukanaoya/Desktop/programming/kaggle/competition-titanic/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: 0.8036 (std: 0.0125)\n",
      "DecisionTree: 0.7555 (std: 0.0922)\n",
      "RandomForest: 0.8193 (std: 0.0217)\n",
      "GradientBoosting: 0.7757 (std: 0.0793)\n",
      "AdaBoost: 0.7689 (std: 0.0681)\n",
      "SVC: 0.6386 (std: 0.0128)\n",
      "KNeighbors: 0.5398 (std: 0.0924)\n",
      "GaussianNB: 0.7722 (std: 0.0318)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nLogisticRegression: 0.8047 (std: 0.0122)\\nDecisionTree: 0.7555 (std: 0.0922)\\nRandomForest: 0.8138 (std: 0.0304)\\nGradientBoosting: 0.7757 (std: 0.0793)\\nAdaBoost: 0.7689 (std: 0.0681)\\nSVC: 0.6386 (std: 0.0128)\\nKNeighbors: 0.5398 (std: 0.0924)\\nGaussianNB: 0.7722 (std: 0.0318)\\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    AdaBoostClassifier,\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 各モデルのインスタンスを作成\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000, random_state=0),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(random_state=0),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=0),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(n_estimators=100, random_state=0),\n",
    "    \"AdaBoost\": AdaBoostClassifier(n_estimators=100, random_state=0),\n",
    "    \"SVC\": SVC(probability=True, random_state=0),\n",
    "    \"KNeighbors\": KNeighborsClassifier(),\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "}\n",
    "\n",
    "# データの分割\n",
    "known_data = df[df.Survived.notnull()]\n",
    "X_known = known_data.drop(\"Survived\", axis=1).values\n",
    "y_known = known_data[\"Survived\"].values\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_known, y_known, random_state=0)\n",
    "\n",
    "# モデルの精度比較\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X_known, y_known, cv=5, scoring=\"accuracy\")\n",
    "    print(f\"{name}: {scores.mean():.4f} (std: {scores.std():.4f})\")\n",
    "\n",
    "\"\"\"\n",
    "LogisticRegression: 0.8047 (std: 0.0122)\n",
    "DecisionTree: 0.7555 (std: 0.0922)\n",
    "RandomForest: 0.8138 (std: 0.0304)\n",
    "GradientBoosting: 0.7757 (std: 0.0793)\n",
    "AdaBoost: 0.7689 (std: 0.0681)\n",
    "SVC: 0.6386 (std: 0.0128)\n",
    "KNeighbors: 0.5398 (std: 0.0924)\n",
    "GaussianNB: 0.7722 (std: 0.0318)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f_/5hh5787972x33swmy27z8q0m0000gn/T/ipykernel_81277/2329614662.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  submit[\"Survived\"] = model.predict(X_unknown).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# RandomForestを使用して提出用データの作成\n",
    "model = models[\"RandomForest\"]\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "score = model.score(X_valid, y_valid)\n",
    "print(\"Validation Accuracy: {:.4f}\".format(score))\n",
    "\n",
    "\n",
    "# 提出用データの作成\n",
    "unknown_data = df[df.Survived.isnull()]\n",
    "X_unknown = unknown_data.drop(\"Survived\", axis=1).values\n",
    "submit = test_df[[\"PassengerId\"]]\n",
    "submit[\"Survived\"] = model.predict(X_unknown).astype(int)\n",
    "submit.to_csv(\"submit2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
